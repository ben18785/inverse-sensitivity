\section{Discussion}
\label{sec:discussion}
Determining the cause of variability in cellular processes is crucial in many applications, ranging from bioengineering to drug development. In this paper, we introduce a Bayesian method for estimating cellular heterogeneity from ``snapshot'' measurements of cellular properties, taken at discrete intervals during experiments. Our approach assumes what we call a ``heterogeneous ordinary differential equation'' (HODE) framework, in which biochemical processes in all cells are governed by a common ODE. In HODEs, each cell has different rate parameter values, causing a variety of measurements to be obtained across cells. In this framework, estimating heterogeneity in cellular processes amounts to determining the probability distributions of parameter values of the governing ODE. Our method of estimation is a two-step Monte Carlo sampling process we term ``Contour Monte Carlo'' (CMC), which does not require the number of cell clusters to be provided before estimation, unlike in other approaches. CMC can be used to process high volumes of individual cellular measurements since the framework involves fitting a kernel density estimator to raw experimental data and using these distributions rather than data as the target outcome. CMC can handle arbitrary multivariate structure in measured outputs, meaning it can capture correlations between the same cellular species at different timepoints or, for example, contemporaneous correlations between different cellular compartments. Being a Bayesian approach, CMC uses prior distributions over parameter values to ensure uniqueness of the posterior distribution, allowing pre-experimental knowledge to be used to improve estimation robustness. The flexible and robust framework that CMC provides means it can be used to perform automatic inference for wide-ranging systems of practical interest.

Our approach also provides a natural way to test that the process is working satisfactorily. Feeding posterior parameter samples obtained by CMC into forward model simulations results in a distribution of output values which can be compared to the target. Indeed, we have found this comparison indispensable in applying CMC in practice and include it as the last step in the CMC algorithm (Algorithm \ref{alg:cmc}). Discrepancies between the target output distribution and its CMC approximation can occur either as a result of poor estimates of the ``contour volume distribution'' in the first stage of the algorithm or due to insufficient MCMC samples in the second. Either of these issues are often easily addressed by increasing sample sizes or changing hyperparameter settings for the kernel density estimator. Although kernel density estimation in high dimensional spaces remains an open research problem, we have found vine copula kernel density estimation works well for the dimensionality of output measurements we investigate here \cite{nagler2016evading}.

Failure to reproduce a given output distribution can also indicate that the generating model (the priors and the forward model) are incongruent with experimental results. This may either be due to misspecification of the ODE system or because the assumption of a deterministic forward model is inappropriate. Our approach currently assumes that output variation is dominated by cellular variation in the parameter values of the underlying ODE, with measurement noise making a negligible contribution. Whether this is a reasonable assumption depends on the system under investigation and, more importantly, on experimental details. We recognise that neglecting measurement noise when it is, in fact, important in determining observed data means CMC will overstate cellular variation. It may also mean that some output distributions cannot be obtained by our model system (i.e. HODEs without noise). Future work incorporating a stochastic noise process or, more generally, including stochastic cellular mechanisms is thus likely to be worthwhile.

In Figure \ref{fig:workflow}, we present the workflow for our approach, which includes as its last step comparing output samples with the target distribution. As discussed above, if output samples do not correspond with the target, this may indicate that a model isn't fit for purpose. Conversely, if there is correspondence with the target distribution, it is possible that a simplified model -- with (say) one or more fewer parameters -- could also recapitulate the same results. Thus, a process of repeated rounds of model simplification then CMC could be pursued to simplify a model until output samples no longer correspond with the target. The most parsimonious model would then be the simplest case where the output samples still match the target. We note however, that such an approach may be dangerous if the most parsimonious model is then used to predict the distributions of other functionals.

Whilst we have illustrated our approach by fitting ODE models to data, we recognise that our approach is applicable to deterministic forward models in general. These include a large swathe of models used in computational biology, such as partial differential equations and difference equations. Similarly, whilst we have illustrated our approach by fitting to models with time-invariant parameters, it could also be used to determine how parameters vary throughout the course of an experiment - provided the dynamic evolution of parameter values is itself parameterised.

We have labelled our approach as Bayesian since it involves explicit estimation of probability distributions and requires priors. We recognise, however, that it is not of the form used in traditional Bayesian inference. This is because, rather than aiming to formulate a model that describes output observations, our approach aims to recapitulate output \emph{distributions}. Others \cite{BJW-18}, (including us \cite{lambert2018inverse}), have considered similar problems before; perhaps most notably by Albert Tarantola in his landmark work on inverse problem theory (see, for example, \cite{tarantola2005inverse}). In Tarantola's framework, a joint input parameter and output space is considered, where prior knowledge and experimental theory combine elegantly to produce a posterior distribution whose marginal output distribution is a weighted ``conjunction'' of various sources of information. This work has seen considerable interest in areas such as the geosciences \cite{mosegaard1995monte,vukicevic2008analysis}, and we propose that Tarantola's approach may prove useful for the biosciences.


The natural world is rife with variation, and mathematical models represent frameworks for understanding its causes. Typically, the state of biological knowledge is such that one effect -- a given pattern of variation -- has many possible causes. Observational or experimental data can be used to apportion weight to each cause, in a process that amounts to solving an inverse problem. The approach we describe here follows the Bayesian paradigm of inverse problem solving where uncertainty in potential causes (i.e. parameter values) is described using probability distributions. Here, we illustrate the worth of our method by using it to estimate cellular heterogeneity in biochemical processes. However, it could equally be used to invert other classes of under-determined systems arising elsewhere. Contour Monte Carlo provides an automatic framework for performing inference on such under-determined systems, and the use of priors allows for robust and precise parameter estimation unattainable through the data alone.

