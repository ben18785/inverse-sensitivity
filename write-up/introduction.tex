\section{Introduction}
Variation, as opposed to homogeneity, is the rule rather than exception in biology. Indeed, without variation, biology as a discipline would not exist, since as evolutionary biologist JBS Haldane wrote, variation is the ``raw material" of evolution. The Red Queen Hypothesis asserts organisms must continually evolve in order to survive when pitted against other - also evolving - organisms \cite{ridley1994red}. A corollary of this hypothesis is that multicellular organisms should evolve cellular phenotypic heterogeneity to allow faster adaptation to changing environments, which may explain the observed variation in a range of biological systems \cite{fraser2009chance}. Whilst cell population variation can confer evolutionary advantages, it can be costly in other circumstances. In biotechnological processes, heterogeneity in cellular function can reduce yields of biochemical products \cite{delvigne2014metabolic}. In human biology, variation across cells can enable pathologies to develop; it can also frustrate treatment of illness because key subpopulations are missed by medical interventions that target ``average'' cell properties. For example, cellular heterogeneity helps some cancerous tumours to persist \cite{gatenby2007cellular} and can make tumours more likely to evolve resistance to chemotherapies \cite{altrock2015mathematics}. To discern whether observed variation is benign or requires remedy, methods of analysis are needed that can quantify and help to understand its source.

Mathematical models are essential tools for understanding cellular systems, whose emergent properties are the result of a nexus of interactions between actors. Perhaps the simplest flavour of mathematical model used in biological systems is an ordinary differential equation (ODE) that aggregates individual actors into compartments according to structure or function, and seeks to model the mean behaviour of each compartment. Data from population-averaged experimental assays can determine whether such models faithfully reproduce system behaviours and can be used to understand the structure of complex metabolic, signalling and transcriptional networks. The worth of such ``population average'' ODE models depends on whether averages mask substantial differences in individual behaviour \cite{altschuler2010cellular}. In some cases, differences in cellular protein abundances due to biochemical ``noise" are not biologically meaningful \cite{elowitz2002stochastic} and the system is well described by average cell behaviour. In others, there are functional consequences. For example, a laboratory study demonstrated that subpopulations of clonally-derived hematopoietic progenitor cells with low expression of a stem cell marker, diverged into a separate blood lineage from those with high expression \cite{chang2008transcriptome}.

Many modelling frameworks are available to describe cell population heterogeneity, with each posing different challenges for parameter inference. A recent review is presented in \cite{waldherr2018estimation}. These approaches include modelling biochemical processes stochastically, where properties of ensembles of cells are represented by probability distributions that evolve according to chemical master equations. See \cite{erban2007practical} for a tutorial on stochastic simulation of reaction diffusion processes. Alternatively, population balance equations (PBEs) are typically partial integro-differential equations that determine the dynamics of the ``number density" of differing cell types. In PBEs, cell properties are represented as points in $\mathbb{R}^n$, with each dimension corresponding to a different attribute. These attributes include parameters controlling cell life - for example, their rate of death and division, which vary according to a cell's location in this ``attribute'' space. These functional differences control the rate at which cells progress through life, which is represented by a ``flow'' of cells from certain areas of attribute space to others - like chemicals diffusing down a concentration gradient. With PBEs, observed variation at a point in time is due to the initial spread of cells across attribute space coupled with the differing dynamics of cells in different areas of this space. See \cite{ramkrishna2014population} for an introduction to PBEs.

Here, we suppose heterogeneity in quantities of interest across cells is generated by idiosyncratic variation in the rates of cellular processes. The modelling approach we follow is similar to that of \cite{dixit2018maximum} and is based on an ODE framework. In our model, each cell evolves according to an ODE, with its progression directed by parameters whose value varies between cells. To our knowledge, this flavour of model is unnamed, so, for sake of reference, we call them ``heterogenous ODE" models (HODEs). In HODEs, the aim of inference is to estimate distributions of parameter values across cells consistent with observations. A benefit of using HODEs is that these models are computationally straightforward to simulate and, arguably, simpler to parameterise than PBEs. By using HODEs, we assume that most observed variation comes from differences in biological processes across cells, not inherent stochasticity in biochemical reactions within cells as is assumed when employing stochastic simulations algorithms.

Inference for HODEs is problematic due, partly, to the experimental hurdles involved with generating data of sufficient standard. Unlike models which represent a population by a single scalar ODE, since HODEs are individual-based, they ideally require individual cell data for estimation. A widely-used method for generating such data is flow cytometry, where a large number of cells are streamed individually through a laser beam, and, for example, the concentrations of fluorescently-labelled proteins are measured \cite{telford2012flow}. Other experimental techniques, including Western blotting and cytometric fluorescence microscopy, can also generate single cell measurements \cite{hughes2014single,hasenauer2011identification}. These experimental methods are all, however, destructive, meaning individual cells are sacrificed during measurement, and observations at each time point hence represent \emph{``snapshots"} of the underlying population \cite{hasenauer2011identification}. These snapshots can be described by histograms \cite{dixit2018maximum} or density functions \cite{waldherr2018estimation} fit to measurements of quantities of interest. Since HODEs assume the state of each cell evolves continuously over time, experimental data tracing individual cell trajectories through time constitutes a richer data resource. \textcolor{blue}{Fluorescent Recovery After Photo-bleaching (FRAP) is one such method, which follows the time-dependent response of cells after an initial bleaching \cite{karlsson2015nonlinear}. Methods exists, broadly under the banner of ``nonlinear mixed effects models'', which uses cell trajectories - individual time series of cellular quantities - to estimate both cellular variation and qualities of measurement noise. See, for example, \cite{karlsson2015nonlinear,zechner2014scalable,dharmarajan2019simple}.} The demands of obtaining such data are, however, higher and typically involve either tracking individual cells through imaging methods \cite{hilsenbeck2016software}, or trapping cells in a spatial position where they can be monitored over time \cite{fritzsch2012single}. \textcolor{blue}{Since typically fitting mixed effect models requires more than one observation per cell, they} impose severe restrictions on experimental practices meaning they cannot be used in many circumstances, including for online monitoring of biotechnological processes or analysis of \textit{in vivo} studies. \textcolor{blue}{``Snapshot''} data continues to play an important role for determining cell level variability in many applications \textcolor{blue}{and in this paper we restrict analysis to only such data.}

By fitting HODES to snapshot data, cellular variability can be estimated and a number of approaches have been proposed for doing so. In HODEs, parameter values vary across cells according to a to-be-determined probability distribution, and the solution to the inverse problem requires solving the cell-specific ODE system many times for each individual. The count of cells in experiments typically exceeds $\sim10^4$ \cite{hasenauer2011identification}, so approaches where the computational burden scales with this count are usually infeasible. To avoid this burden, some approaches fit probability densities to raw snapshot data and use these densities, rather than raw data, for estimation \cite{hasenauer2011identification,hasenauer2014ode,loos2018hierarchical,dixit2018maximum}. We follow this approach here. We now briefly describe the existing approaches for using HODE models to estimate cell population heterogeneity. Hasenauer et al. (2011) present a Bayesian approach to inference for HODEs, which models the input parameter space using an ansatz of a mixture of densities of chosen types. The authors then use their method to reproduce population substructure on synthetic data generated from a model of tumour necrosis factor stimulus. Hasenauer et al. (2014) use mixture models to model subpopulation structure in snapshot data with multiple-start local optimisation employed to maximise the non-convex likelihood, which they then apply to synthetic and real data from signalling pathway models. Loos et al. (2018) also use mixture models to represent subpopulation structure and use maximum likelihood to estimate both within- and between-subpopulation variability, which permits fitting to multivariate output distributions with complex correlation structures. Dixit et al. (2018) assign observations into discrete bins, then choose likelihood distributions according to the maximum entropy criterion, which they then use to estimate cell variability within a Bayesian framework.

Our framework is Bayesian although it is distinct from the approach used to fit many dynamic models, since we assume output variation arises from parameter heterogeneity across cells, with no contribution from measurement noise. The approach is, hence, most suitable when measurement error is minimal. Additionally, our approach is suitable only for underdetermined models \textcolor{blue}{- which we define as the case where there are fewer parameters than output quantities of interest. Since the generation of snapshots is expensive, it is often the case that fewer observables are recorded than parameters. Hence, we believe that this restriction does not present particular issue to the generalisability of our approach.} Our method is a two-step Monte Carlo approach, which, for reasons described in \S \ref{sec:method}, we call ``Contour Monte Carlo'' (CMC). Unlike many existing methods, CMC is straightforward to implement and does not require extensive computation time. In CMC, prior probability distributions are used in place of ansatz densities. It also does not require the number of cell clusters be chosen beforehand, rather, subpopulations emerge as modes in the posterior parameter distributions. Like \cite{loos2018hierarchical}, CMC can fit multivariate snapshot data and unlike \cite{dixit2018maximum}, does not use discrete bins to model continuous data. As more experimental techniques elucidating single cell behaviour are developed, interest in models describing measurement snapshots should follow. We argue that due to its simplicity and generality, CMC can be used to perform inference on the proliferation of rich single cell data and, thus, is a useful addition to the modeller's toolkit.


\underline{Outline of the paper}: In \S \ref{sec:method}, we describe our probabilistic model of the inverse problem and detail the CMC algorithm for generating samples from the posterior parameter distribution. In \S \ref{sec:results}, we use CMC to estimate cell population heterogeneity in three systems of biological interest.


