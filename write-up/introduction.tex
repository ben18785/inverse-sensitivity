\section{Introduction}
Variation, as opposed to homogeneity, is the rule rather than exception in biology. Indeed, without variation, biology as a discipline would not exist, since as evolutionary biologist JBS Haldane wrote, variation is the ``raw material" of evolution. The Red Queen Hypothesis asserts that organisms must continually evolve in order to survive when pitted against other - also evolving - organisms \cite{ridley1994red}. A corollary of this hypothesis is that multicellular organisms should evolve cellular phenotypic heterogeneity to allow faster adaptation to changing environments, which may explain the observed variation in a range of biological systems \cite{fraser2009chance}. Whilst cell population variation can confer evolutionary advantages, it can also be costly in other circumstances. In biotechnological processes, heterogeneity in cellular function can lead to reduced yields of biochemical products \cite{delvigne2014metabolic}. In human biology, variation across cells can enable pathologies to develop and also prevents effective medical treatment, since medical interventions typically aim to steer modal cellular properties and hence fail to influence key subpopulations. For example, cellular heterogeneity likely assists some cancerous tumours to persist \cite{gatenby2007cellular} and facilitates evolution of resistance to chemotherapies \cite{altrock2015mathematics}. Identifying and quantifying sources of variation in populations of cells is important for wide ranging applications to discern whether the variability is benign or alternatively requires remedy.

Mathematical models are essential tools for understanding cellular systems, whose emergent properties are the result of complex interactions between various actors. Perhaps the simplest flavour of mathematical model used in biological systems is an ordinary differential equation (ODE) that lumps individual actors into partitions according to structure or function, and seeks to model the mean behaviour of each partition. Data from population-averaged experimental assays can be a powerful resource to understand whether such models faithfully reproduce system behaviours and can allow quantification of the interactions of various cellular components of complex metabolic, signalling and transcriptional networks. The worth of such models however is determined by whether averages mask differences in behaviour of individual cells that result in functional consequences \cite{altschuler2010cellular}. In some cases, differences in cellular protein abundances due to biochemical ``noise" may not be meaningful biologically \cite{elowitz2002stochastic} and mean cell behaviour suffices as a description of the system, whereas in others there are functional consequences. For example, a recent study demonstrated that subpopulations of clonally derived hematopoietic progenitor cells with low or high expression of a particular stem cell marker produced different blood lineages \cite{chang2008transcriptome}.

To accommodate cell population heterogeneity in mathematical models, a variety of modelling choices are available, each posing different challenges for parameter inference. A recent review is presented in \cite{waldherr2018estimation}. These approaches include modelling biochemical processes stochastically, with properties of ensembles of cells represented by probability distributions evolving according to chemical master equations (see \cite{erban2007practical} for a tutorial on stochastic reaction-diffusion processes; RDEs). Alternatively, population balance equations (PBEs) can be used to dictate the evolution of the ``number density" of differing cell types, whose properties are represented as points in $\mathbb{R}^n$ which, in turn, affect their function, including their rate of death and cell division (see \cite{ramkrishna2014population} for an introduction to PBEs). In a PBE approach, variation in measured quantities results primarily from differing functional properties of heterogeneous cell types and variable initial densities of each type.

The approach we follow here is similar to that of \cite{dixit2018maximum}, wherein dynamic cellular variation is generated by describing the evolution of each cell's state using an ODE, but with individual cell differences in the rate parameters of the process. To our knowledge, this flavour of model is unnamed and so, for sake of reference, we term them ``heterogenous ODE" models (HODEs). In HODEs, the aim of inference is to estimate the distributions of parameter values across cells that are consistent with observed distributions of measurements at various timepoints. A benefit of using HODEs to model cell heterogeneity is that these models are computationally straightforward to simulate and, arguably, simpler to parameterise than PBEs. An implicit assumption in this modeling approach is that the predominant source of variation is due to differences in biological processes across cells, not inherent stochasticity in biochemical reactions within cells, as in stochastic RDEs.

The difficulty of parameter inference for HODEs is partly due to experimental hurdles in generating data of sufficient quality to allow identification. Unlike models which represent a population by a single scalar ODE, since HODEs are individual-based, they ideally require individual cell data for estimation. A widely-used method for generating data for individual cells is flow cytometry, where a large number of cells are streamed individually through a laser beam and, for example, abundance measurements are made of proteins labelled with fluorescent markers \cite{telford2012flow}. Alternatively, experimental techniques such as Western blotting and cytometric fluorescence microscopy can generate single cell measurements \cite{hughes2014single,hasenauer2011identification}. A property of these experimental methods is that they are destructive, meaning that individual cells are sacrificed as part of the measurement process. This means that the measurements of cell properties obtained at a certain point in time represent what are termed \emph{``snapshots"} of the underlying population \cite{hasenauer2011identification}. These snapshots are often described by histograms \cite{dixit2018maximum} or density functions \cite{waldherr2018estimation} fit to the underlying data at different points in time. Since HODEs represent the underlying state of individual cells as evolving continuously with time, experimental data tracing individual cell trajectories through time would constitute a richer data resource. The demands of obtaining this data are higher however and typically involve either tracking individual cells through imaging methods \cite{hilsenbeck2016software} or trapping cells in a spatial position where their individual dynamics can be readily monitored \cite{fritzsch2012single}. These techniques impose restrictions on experimental practices meaning they cannot be realised in all circumstances, including for online monitoring of biotechnological processes or analysis of \textit{in vivo} studies. For this reason, ``snapshot'' data continues to play an important role for determining cell level variability in many applications.

A variety of approaches have been proposed to estimate cell-to-cell variability by fitting HODE models to snapshot data. In HODEs, parameter values vary across cells according to a to-be-determined probability distribution, meaning that in order to solve the exact inverse problem, the underlying ODE system needs to be simulated for each individual. Since the numbers of cells in these experiments are typically $>\sim10^4$ \cite{hasenauer2011identification}, this usually precludes exact inference due to its computational burden and instead the raw snapshot data is approximated by probability densities \cite{hasenauer2011identification,hasenauer2014ode,loos2018hierarchical,dixit2018maximum}. Hasenauer et al. (2011) presents a Bayesian approach to inference for HODEs, which models the input parameter space using mixtures of ansatz densities. The authors then use their method to reproduce population substructure on synthetic data generated from a model of tumour necrosis factor stimulus. Hasenauer et al. (2014) uses mixture models to model subpopulation structure in snapshot data with multiple-start local optimisation employed to maximise the non-convex likelihood, which they then apply to synthetic and real data from signalling pathway models. Loos et al. (2018) also uses mixture models to represent subpopulation structure and a maximum likelihood approach that allows for estimation of within- and between-subpopulation variability which permits fitting to multivariate output distributions with complex correlation structures. Dixit et al. (2018) discretises cell abundances into bins, then uses a maximum entropy approach as part of a Bayesian framework to fit the distribution representing cell-to-cell variability.

The framework we present here is Bayesian although is distinct from the traditional Bayesian inferential paradigm used to fit many dynamic models, since the source of stochasticity arises solely due to cell-to-cell parameter variation and not due to measurement noise. Our approach is hence most suitable when measurement error is a minor contributor to observed experimental variability. Our computational method is a two-step Monte Carlo approach which, for reasons described in \S \ref{sec:method}, we term ``Contour Monte Carlo'' (CMC). Unlike many of the existing methods, CMC is relatively computationally straightforward to implement and does not require extensive computation time. CMC uses MCMC in its second step to sample from the posterior distribution over parameter values and hence does not require specification of ansatz densities. It also does not require \textit{a priori} representation of subpopulation structure using mixture components, rather, subpopulations emerge as modes in the posterior parameter distributions. Like \cite{loos2018hierarchical}, CMC can fit multivariate snapshot data and unlike \cite{dixit2018maximum}, does not require this data to be discretised into bins. As more experimental techniques are developed which elucidate single cell behaviour, there is likely to be more interest in methods which can be used to recapitulate the observed snapshots. We argue that due to its simplicity and generality, CMC is a useful addition to the modeller's toolkit and can be used to perform inference on the proliferation of rich single cell data.


\underline{Outline of the paper}: In \S \ref{sec:method}, we present the details of our methodological framework and detail the CMC algorithm used to generate samples from the posterior parameter distribution. In \S \ref{sec:results}, we use CMC to estimate cell population heterogeneity in three systems of biological interest.


